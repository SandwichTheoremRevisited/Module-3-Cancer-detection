{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da424d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 151577 to 121931\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      10000 non-null  object\n",
      " 1   label   10000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 234.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "\n",
    "train_labels.sort_values(by='id', axis=0, inplace=True)\n",
    "\n",
    "train_labels = train_labels[0:10000]\n",
    "\n",
    "train_labels.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adf5132",
   "metadata": {},
   "source": [
    "The training dataset consists of $220,025$ pathology images, each of which is denoted by an `id` and has been assigned a `label`, either $0$ or $1$, indicating the presence of cancer. Due to memory limitations, I will only be considering the first $10,000$ samples. The goal here will be to train a convolutional neural network to successfully detect cancer given a pathology image by classifying it into one of these two categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c466b75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5936\n",
      "4064\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.sum(train_labels['label'] == 0))\n",
    "print(np.sum(train_labels['label'] == 1))\n",
    "print(5936+4064)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfbcb73",
   "metadata": {},
   "source": [
    "Of the $10,000$ training images, $5,936$ have a `label` of $0$, indicating the absence of cancer, and the remaining $4,064$ have a `label` of $1$, indicating the presence of cancer. This distribution is well-balanced, meaning we should not have any problems using accuracy as an evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5025f242",
   "metadata": {},
   "source": [
    "As noted on Kaggle, the dataset contains no duplicate images, and every image has a valid `label`. Therefore the data is clean and ready for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5857e970",
   "metadata": {},
   "source": [
    "For this project, I am going to make use of the following architecture:\n",
    "\n",
    "Since the image size is $96 \\times 96$ pixels, we will start with a $96 \\times 96 \\times 3$ matrix. There will be three convolutional layers: the first layer will have $32$ $3 \\times 3$ filters, the second layer will have $64$ $3 \\times 3$ filters and the third layer will have $128$ $3 \\times 3$ filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aebb42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "directory = 'train'\n",
    "\n",
    "n=0\n",
    "\n",
    "X_train_whole = []\n",
    "\n",
    "for i, filename in enumerate(os.listdir(directory)):\n",
    "    if n == 10000:\n",
    "        break\n",
    "        print(\"hit 10000\")\n",
    "    f = os.path.join(directory, filename)\n",
    "\n",
    "    if os.path.isfile(f):\n",
    "        img = cv2.imread(f)\n",
    "        pix = np.array(img)\n",
    "        pix = pix.reshape(96,96,3)\n",
    "        #print(pix_arr)\n",
    "        #print(pix_arr.shape)\n",
    "        X_train_whole.append(pix)\n",
    "        n+=1\n",
    "    else:\n",
    "        print('no file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b3c963",
   "metadata": {},
   "source": [
    "The above will load the images and turn them into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df25cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31882b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4ef2355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8505248476124214785\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5912018944\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5942763675066565448\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:07:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad25bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,valid_X,train_label,valid_label = train_test_split(X_train_whole, train_labels['label'], test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bde06941",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = tf.constant(X_train)\n",
    "valid_X_t = tf.constant(valid_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b641ddad",
   "metadata": {},
   "source": [
    "In the cell above, I split the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe0b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input,Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f00884",
   "metadata": {},
   "source": [
    "I am using Keras to implement this architecture. I am making use of the leaky ReLU activation function, and the final output layer will use a sigmoid function, as is appropriate for a binary classification problem. The batch size is $64$, and I will train the network for $20$ epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1559de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',input_shape=(96,96,3),padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='linear',padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='linear',padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(Dense(num_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cd3fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b9c6455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 96, 96, 32)        896       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 96, 96, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2359424   \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,452,801\n",
      "Trainable params: 2,452,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5593bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136447    1\n",
      "161920    0\n",
      "126742    1\n",
      "20905     0\n",
      "161193    0\n",
      "         ..\n",
      "216756    0\n",
      "202679    0\n",
      "184402    1\n",
      "152958    1\n",
      "56545     0\n",
      "Name: label, Length: 8000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_label_t = train_label\n",
    "print(train_label_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fa33613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[157  77 124]\n",
      "   [161  79 128]\n",
      "   [162  77 129]\n",
      "   ...\n",
      "   [106  30  88]\n",
      "   [134  48 110]\n",
      "   [134  37 103]]\n",
      "\n",
      "  [[158  73 123]\n",
      "   [146  61 113]\n",
      "   [147  59 113]\n",
      "   ...\n",
      "   [170  90 157]\n",
      "   [176  82 153]\n",
      "   [191  91 163]]\n",
      "\n",
      "  [[188  97 152]\n",
      "   [171  80 135]\n",
      "   [163  74 130]\n",
      "   ...\n",
      "   [189 103 181]\n",
      "   [226 131 212]\n",
      "   [230 126 209]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[223 213 219]\n",
      "   [246 229 242]\n",
      "   [206 181 201]\n",
      "   ...\n",
      "   [231 215 232]\n",
      "   [215 199 216]\n",
      "   [221 205 223]]\n",
      "\n",
      "  [[212 201 209]\n",
      "   [213 196 209]\n",
      "   [255 246 255]\n",
      "   ...\n",
      "   [238 219 246]\n",
      "   [227 207 236]\n",
      "   [244 224 253]]\n",
      "\n",
      "  [[222 211 219]\n",
      "   [230 213 226]\n",
      "   [252 225 245]\n",
      "   ...\n",
      "   [219 198 231]\n",
      "   [255 242 255]\n",
      "   [150 128 163]]]\n",
      "\n",
      "\n",
      " [[[235 231 243]\n",
      "   [228 223 238]\n",
      "   [220 212 229]\n",
      "   ...\n",
      "   [229 230 228]\n",
      "   [229 230 228]\n",
      "   [229 230 228]]\n",
      "\n",
      "  [[213 210 219]\n",
      "   [219 215 226]\n",
      "   [231 224 237]\n",
      "   ...\n",
      "   [229 230 228]\n",
      "   [229 230 228]\n",
      "   [229 230 228]]\n",
      "\n",
      "  [[234 231 233]\n",
      "   [230 226 231]\n",
      "   [225 221 227]\n",
      "   ...\n",
      "   [229 230 228]\n",
      "   [229 230 228]\n",
      "   [229 230 228]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[245 225 238]\n",
      "   [232 211 226]\n",
      "   [248 225 247]\n",
      "   ...\n",
      "   [229 229 229]\n",
      "   [231 229 228]\n",
      "   [231 230 226]]\n",
      "\n",
      "  [[247 232 236]\n",
      "   [201 184 193]\n",
      "   [227 208 223]\n",
      "   ...\n",
      "   [229 230 228]\n",
      "   [231 230 226]\n",
      "   [231 231 225]]\n",
      "\n",
      "  [[216 202 203]\n",
      "   [219 204 208]\n",
      "   [236 218 231]\n",
      "   ...\n",
      "   [229 230 226]\n",
      "   [229 231 225]\n",
      "   [231 232 223]]]\n",
      "\n",
      "\n",
      " [[[225 217 234]\n",
      "   [229 217 239]\n",
      "   [242 226 255]\n",
      "   ...\n",
      "   [160 136 171]\n",
      "   [186 165 204]\n",
      "   [227 209 248]]\n",
      "\n",
      "  [[196 187 207]\n",
      "   [220 207 231]\n",
      "   [173 156 189]\n",
      "   ...\n",
      "   [177 153 188]\n",
      "   [182 164 201]\n",
      "   [169 154 192]]\n",
      "\n",
      "  [[186 174 196]\n",
      "   [227 214 240]\n",
      "   [186 169 203]\n",
      "   ...\n",
      "   [222 200 235]\n",
      "   [252 236 255]\n",
      "   [226 214 250]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[240 242 242]\n",
      "   [238 240 240]\n",
      "   [237 239 239]\n",
      "   ...\n",
      "   [249 230 255]\n",
      "   [228 200 236]\n",
      "   [217 182 222]]\n",
      "\n",
      "  [[247 249 249]\n",
      "   [241 243 243]\n",
      "   [236 238 238]\n",
      "   ...\n",
      "   [249 228 255]\n",
      "   [223 196 230]\n",
      "   [152 119 153]]\n",
      "\n",
      "  [[252 254 254]\n",
      "   [244 246 246]\n",
      "   [236 238 238]\n",
      "   ...\n",
      "   [239 220 255]\n",
      "   [177 152 186]\n",
      "   [ 85  54  85]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[234 191 248]\n",
      "   [118  70 128]\n",
      "   [104  50 109]\n",
      "   ...\n",
      "   [ 95  45 103]\n",
      "   [129  81 139]\n",
      "   [226 181 238]]\n",
      "\n",
      "  [[236 203 254]\n",
      "   [115  77 129]\n",
      "   [122  80 135]\n",
      "   ...\n",
      "   [126  79 141]\n",
      "   [131  87 148]\n",
      "   [145 101 162]]\n",
      "\n",
      "  [[188 168 213]\n",
      "   [219 196 241]\n",
      "   [146 116 165]\n",
      "   ...\n",
      "   [128  83 146]\n",
      "   [144 101 164]\n",
      "   [131  88 151]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255 232 255]\n",
      "   [255 233 255]\n",
      "   [255 242 255]\n",
      "   ...\n",
      "   [148 139 166]\n",
      "   [205 206 234]\n",
      "   [209 217 246]]\n",
      "\n",
      "  [[205 169 215]\n",
      "   [120  90 131]\n",
      "   [169 150 183]\n",
      "   ...\n",
      "   [165 136 181]\n",
      "   [190 175 219]\n",
      "   [228 224 255]]\n",
      "\n",
      "  [[117  74 131]\n",
      "   [143 108 158]\n",
      "   [162 141 179]\n",
      "   ...\n",
      "   [170 122 180]\n",
      "   [211 180 235]\n",
      "   [143 122 177]]]\n",
      "\n",
      "\n",
      " [[[ 93  61 118]\n",
      "   [ 92  58 122]\n",
      "   [ 78  39 114]\n",
      "   ...\n",
      "   [ 74  43  98]\n",
      "   [103  65 113]\n",
      "   [ 95  50  93]]\n",
      "\n",
      "  [[108  72 114]\n",
      "   [ 81  43  93]\n",
      "   [ 80  38  99]\n",
      "   ...\n",
      "   [ 95  51 104]\n",
      "   [103  48  97]\n",
      "   [ 93  31  77]]\n",
      "\n",
      "  [[ 67  25  50]\n",
      "   [ 41   0  29]\n",
      "   [ 86  39  85]\n",
      "   ...\n",
      "   [ 89  35  88]\n",
      "   [ 78  13  62]\n",
      "   [ 96  22  70]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 76  35 110]\n",
      "   [175 136 212]\n",
      "   [198 158 240]\n",
      "   ...\n",
      "   [129  86 159]\n",
      "   [148 104 173]\n",
      "   [129  85 152]]\n",
      "\n",
      "  [[ 78  32 109]\n",
      "   [112  69 150]\n",
      "   [166 123 210]\n",
      "   ...\n",
      "   [ 96  58 130]\n",
      "   [120  78 149]\n",
      "   [ 83  39 110]]\n",
      "\n",
      "  [[128  81 160]\n",
      "   [110  64 147]\n",
      "   [121  79 167]\n",
      "   ...\n",
      "   [102  63 138]\n",
      "   [ 87  47 119]\n",
      "   [102  59 132]]]\n",
      "\n",
      "\n",
      " [[[232 238 249]\n",
      "   [245 243 255]\n",
      "   [222 206 237]\n",
      "   ...\n",
      "   [133 112 145]\n",
      "   [167 148 181]\n",
      "   [227 210 243]]\n",
      "\n",
      "  [[182 177 192]\n",
      "   [229 217 239]\n",
      "   [255 239 255]\n",
      "   ...\n",
      "   [ 85  51  82]\n",
      "   [ 62  31  62]\n",
      "   [240 212 242]]\n",
      "\n",
      "  [[137 115 139]\n",
      "   [255 236 255]\n",
      "   [191 167 199]\n",
      "   ...\n",
      "   [ 64  18  47]\n",
      "   [ 75  34  62]\n",
      "   [245 205 233]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[206 193 219]\n",
      "   [255 247 255]\n",
      "   [175 160 174]\n",
      "   ...\n",
      "   [144 100 139]\n",
      "   [133  87 129]\n",
      "   [188 137 181]]\n",
      "\n",
      "  [[114 109 124]\n",
      "   [222 216 227]\n",
      "   [222 216 221]\n",
      "   ...\n",
      "   [ 52  15  49]\n",
      "   [ 84  37  75]\n",
      "   [143  90 130]]\n",
      "\n",
      "  [[ 72  68  79]\n",
      "   [236 232 237]\n",
      "   [246 241 242]\n",
      "   ...\n",
      "   [110  78 109]\n",
      "   [ 80  34  70]\n",
      "   [ 93  36  75]]]], shape=(8000, 96, 96, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e92889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 14s 31ms/step - loss: 10.8873 - accuracy: 0.6759 - val_loss: 0.5623 - val_accuracy: 0.7240\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.5029 - accuracy: 0.7619 - val_loss: 0.5338 - val_accuracy: 0.7345\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.4865 - accuracy: 0.7728 - val_loss: 0.4676 - val_accuracy: 0.7770\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.4756 - accuracy: 0.7779 - val_loss: 0.4453 - val_accuracy: 0.7965\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4579 - accuracy: 0.7876 - val_loss: 0.4656 - val_accuracy: 0.7785\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.4382 - accuracy: 0.7951 - val_loss: 0.5551 - val_accuracy: 0.7395\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.4172 - accuracy: 0.8085 - val_loss: 0.4750 - val_accuracy: 0.7800\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.3596 - accuracy: 0.8432 - val_loss: 0.4878 - val_accuracy: 0.7840\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.3240 - accuracy: 0.8661 - val_loss: 0.5372 - val_accuracy: 0.7485\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2877 - accuracy: 0.8821 - val_loss: 0.4827 - val_accuracy: 0.7845\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 3s 21ms/step - loss: 0.2366 - accuracy: 0.9065 - val_loss: 0.5965 - val_accuracy: 0.7670\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 3s 20ms/step - loss: 0.1761 - accuracy: 0.9336 - val_loss: 0.6414 - val_accuracy: 0.7730\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.1359 - accuracy: 0.9556 - val_loss: 0.6849 - val_accuracy: 0.7485\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.1187 - accuracy: 0.9571 - val_loss: 0.7509 - val_accuracy: 0.7510\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.0776 - accuracy: 0.9743 - val_loss: 0.8345 - val_accuracy: 0.7235\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.0630 - accuracy: 0.9808 - val_loss: 1.0750 - val_accuracy: 0.7270\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.0336 - accuracy: 0.9906 - val_loss: 1.0552 - val_accuracy: 0.7615\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.0443 - accuracy: 0.9865 - val_loss: 1.0593 - val_accuracy: 0.7360\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.0760 - accuracy: 0.9709 - val_loss: 1.1092 - val_accuracy: 0.7265\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 2s 20ms/step - loss: 0.0526 - accuracy: 0.9822 - val_loss: 1.1751 - val_accuracy: 0.7390\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(X_train_t, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X_t, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c462e9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8000\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(train_label))\n",
    "print(len(valid_X))\n",
    "print(len(valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58ad41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'test'\n",
    "\n",
    "#n=0\n",
    "\n",
    "X_test_whole = []\n",
    "\n",
    "for i, filename in enumerate(os.listdir(directory)):\n",
    "    #if n == 10000:\n",
    "    #    break\n",
    "    #    print(\"hit 10000\")\n",
    "    f = os.path.join(directory, filename)\n",
    "\n",
    "    if os.path.isfile(f):\n",
    "        img = cv2.imread(f)\n",
    "        pix = np.array(img)\n",
    "        pix = pix.reshape(96,96,3)\n",
    "        #print(pix_arr)\n",
    "        #print(pix_arr.shape)\n",
    "        X_test_whole.append(pix)\n",
    "        #n+=1\n",
    "    else:\n",
    "        print('no file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1224c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_t = tf.constant(X_test_whole)\n",
    "\n",
    "pred = model.predict(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006355b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "\n",
    "    img_id = filename[0:-4]\n",
    "    id_list.append(img_id)\n",
    "    print(img_id)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e461d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame({'id' : id_list, 'label' : pred})\n",
    "\n",
    "output = out.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4cfce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
